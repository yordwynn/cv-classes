{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('drive', force_remount=True)\n",
    "\n",
    "# введите имя папки на гугл диске, в которую вы сохранили папку vision,\n",
    "# содержащую .py файлы, а также папки datatasets и classifiers например,\n",
    "# cv/assignments/assignment1/vision/\n",
    "FOLDERNAME = None\n",
    "\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "%cd drive/My Drive\n",
    "%cp -r $FOLDERNAME ../../\n",
    "%cd ../../\n",
    "%cd vision/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd ../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Реализация нейронной сети\n",
    "В этой лабораторной вам нужно будет:\n",
    "* разработать нейронную сеть с полносвязными слоями, которая будет выполнять слассификацию изображений\n",
    "* протестировать сеть на изображениях из выборки CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Этот код нужно запустить для предватирельных настроек\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vision.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # размер изображений\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "Мы будем использовать класс `TwoLayerNet` из файла `vision/classifiers/neural_net.py` для представления нашей нейронной сети. Параметры сети хранятся в переменной класса `self.params`, где ключ - это строка с именем параметра, а значение - массивы (numpy arrays). Ниже мы создаем \"грушечную\" модель и \"игрушенчные\" данные, которые мы будем использовать при разработке нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Создание игрушесной модели и игрушечных данных для разработки\n",
    "# параметер random.seed устанавливается для того, чтобы результаты эеспериментов были повторяемыми\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прямой проход: вычислите оценки для классов\n",
    "Реализуйте первую часть функции `TwoLayerNet.loss`, которая вычисляет оценки для входных изображений.\n",
    "\n",
    "Эта функция находится в файле `vision/classifiers/neural_net.py`, и она очень похожа на функции потерь SVM и Softmax: функция берет данные и параметры и вычисляет оценки для классов, значение функции потерь, градиент функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# Разница должны быть очень маленькой, ~ 1e-5 - 1e-7 (диапазон может отличаться)\n",
    "print('Difference between your scores and correct scores:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прямой проход: вычисление значения функции потерь\n",
    "В этой же функции, `TwoLayerNet.loss`, реализуйте вторую часть, которая вычисляет значение потери."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# Разница должны быть очень маленькой, ~ 1e-10 - 1e-12 (диапазон может отличаться)\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обратный проход\n",
    "Реализуйте функцию до конца. Вам нужно вычислить градиент функции потерь относительно переменных `W1`, `b1`, `W2`, и  `b2`. Имея правильно реализованный прямой проход вы можете отладить обратный проход, сравнивая результаты с численым градиентом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# С помощью градиента, полученного численно, проверьте свою реализацию градиента\n",
    "# Если ваша реализиция верна, разница между вашим градиентом и градиентом,\n",
    "# полученным численно должна быть меньше 1e-8 для градиента по каждой из переменных\n",
    "# W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение сети\n",
    "Для обучения сети мы будем использовать метод стохастического градиентного спуска (stochastic gradient descent, SGD), так же как для классификаторов SVM и Softmax. Допишите пропущенные куски кода в функции `TwoLayerNet.train`. Также вам понадобится реализовать функцию `TwoLayerNet.predict`, так как в процессе обучения вы будете вызывать эту функцию для того чтобы отслеживать точность классификации.\n",
    "\n",
    "Реализовав метод, запустите код ниже для того, чтобы обучить двухслойную сеть на игрушечных данных. Вы должны получить значение потери меньше чем 0,02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_training_loss"
   },
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# отобразим график изменения значения функции потерь с течением времени\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных\n",
    "Теперь, когда вы реализовали сеть, которая проходит все предыдущие тесты, вам необходимо загрузить данные из уже знакомой выборки CIFAR-10 и проверить работу сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "from vision.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Загрузка выборки CIFAR-10 (код ниже уже знаком вам из предыдущих лабораторных)\n",
    "    cifar10_dir = 'vision/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение сети\n",
    "Для обучения сети мы используем метод градиентного спуска. Дополнительно мы будем снижать скорость обучения по мере увеличения количества итераций, чтобы \"не проскочить\" минимальное значение функции потерь. Для этого после каждой эпохи мы будем умножать скорость обучения на снижающий коэффициент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Обучение сети\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "# Тестирование на проверочной выборке\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отладка обучения\n",
    "С параметрами по умолчанию точность классификации на проверочной выборке должна составлять примерно 0.29, что не очень хорошо.\n",
    "\n",
    "Один из способов понять причину того, что модель плохо обучается - это вывести графики для функции потерь и точности в зависимости от номера итерации во время обучения. Точность будем выводить и для обучающей, и для проверочной выборок.\n",
    "\n",
    "Другой способ - визуализировать патаметры, которые мы изучили на первом слое сети. В большинстве сетей, обученных на изображениях первый слой позволяет увидеть какие-то труктурные элементы изображений из обучаюзей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График функции потерь и точность для обучеющей и проверочной выборок\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision.vis_utils import visualize_grid\n",
    "\n",
    "# Визуализация весов сети\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск гиперпараметров\n",
    "\n",
    "**Причины:** Графики выше показывают, что потеря уменьшается линейно, что говорит о том, что скорость обучения может быть слишком низкой. Кроме того, нет разницы между точностью на обучающей и проверочной выборках, отсюда можно предположить, что модель имеет недостаточно параметров, и нужно увеличить их количество (можель плохо изучила признаки тренировочной выборки). С другой стороны, модель с очень большим количеством параметров склонна к переобучению, что может привести к очень большой разнице в точности между обучающей и проверочной выборками.\n",
    "\n",
    "**Поиск:** Поиск гиперпараметров и развитие понимания того, как значения гиперпараметров влияют на точность - это очень важный для использования нейронных сетей навык, который нужно отрабатывать на практике. Ниже вы должны првоести эксперименты с различными значениями гиперпараметров, включая количество скрытых слоев, скорость обучения, количество обучающих эпох и коэффициент регуляризации. Также вы можете поработать с коэффициентом уменьшения скорости обучения (опционально).\n",
    "\n",
    "**Ожидаемый результат:** Ваша цель - достичь точности классификации не менее 48%. Луший результат, который мне удалось достичь - 52-53%. Возможно, у вас выйдет еще лучше. Если вам интересно, вы можете попробовать усовершенствовать сеть, например, убрать некоторые изменения в исходных данных, или использовать нормализацию данных (добавляется как слой сети)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "best_net = None # сохраните в этой переменной лучшую модель\n",
    "\n",
    "#################################################################################\n",
    "# TODO: Найдите гиперпапаметры, используя проверочную выборку. Сохраните лучшую #\n",
    "# обученную модель в перменной best_net.                                        #\n",
    "#                                                                               #\n",
    "# Для того, чтобы отладить сеть вам, возможно, будет полезно использовать       #\n",
    "# графики точности и потерь, которые мы видели выше. Графики для данной модели  #\n",
    "# будут значительно отличаться от графиков \"игрушечной\" модели, которую мы      #\n",
    "# использовали ранее.                                                           #\n",
    "#                                                                               #\n",
    "# Совет: генерируйте несколько значений для каждого гиперпараметра и напишите   #\n",
    "# код, который перебирает возможные сочетания для параметров (посмотрите, какие #\n",
    "# функции Python можно для этого использовать).                                 #\n",
    "#################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "pass\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Объясните, как вы подбирали гиперпараметры, и какие результаты вы получили (с пояснением, почему именно эти гиперпараметры вы считаете наиболее подходящими)**\n",
    "\n",
    "$\\color{blue}{\\textit Ваш ответ:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "val_accuracy"
   },
   "outputs": [],
   "source": [
    "# Выведите точность на проверочной выборке - она должна быть больше 48%\n",
    "val_acc = (best_net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте веса лучшей сети\n",
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск сети на тестовой выборке\n",
    "Когда вы закончили с экспериментами, вам стоит оценть точность классификатора на тестовой выборке. Вы должны получить точность больше 48%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_accuracy"
   },
   "outputs": [],
   "source": [
    "# Print your test accuracy: this should be above 48%\n",
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}